{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mohsinal/example-context-based-recommender-engine?scriptVersionId=122363258\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"### Sentence transformers \nA popular choice for building recommender systems that rely on text data. These models can take in raw text data and transform it into fixed-length vectors that capture the semantic meaning of the text. These vectors can then be used to find similarities and differences between pieces of text, which is useful for tasks like recommendation.\n\nTo build your na√Øve contextual based recommender system using sentence transformers, you will need to follow these general steps:\n\n### Prepare your data: \nCollect and clean the text data that you will be using for your recommender system. This could be a collection of product reviews, news articles, or any other type of text data that you want to use for recommendations.\n\n### Train your sentence transformer:\nYou can either train your own sentence transformer from scratch or use a pre-trained model. Pre-trained models like BERT, RoBERTa, and DistilBERT are already available and can be fine-tuned on your specific dataset to generate embeddings for your text data.\n\n### Generate embeddings:\nUse the trained sentence transformer to generate embeddings for each piece of text in your dataset. These embeddings should capture the semantic meaning of the text and be of a fixed length.\n\n### Find similarities:\nUse a similarity measure, such as cosine similarity, to find the similarity between embeddings for different pieces of text. This will allow you to identify similar pieces of text that could be recommended to users.\n\n### Create a recommendation engine:\nBased on the similarity measure, create a recommendation engine that recommends similar pieces of text to users based on their input.\n\nKeep in mind that this is a very basic approach and there are many ways to improve the performance of your recommender system, such as using more advanced algorithms or incorporating additional features like user preferences or ratings.","metadata":{}},{"cell_type":"markdown","source":"lets install sentence transformers","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2022-08-26T12:52:30.79975Z","iopub.execute_input":"2022-08-26T12:52:30.800357Z","iopub.status.idle":"2022-08-26T12:52:47.533849Z","shell.execute_reply.started":"2022-08-26T12:52:30.800205Z","shell.execute_reply":"2022-08-26T12:52:47.532241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-26T12:52:47.536714Z","iopub.execute_input":"2022-08-26T12:52:47.537124Z","iopub.status.idle":"2022-08-26T12:52:47.550476Z","shell.execute_reply.started":"2022-08-26T12:52:47.537083Z","shell.execute_reply":"2022-08-26T12:52:47.549107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T12:52:47.552069Z","iopub.execute_input":"2022-08-26T12:52:47.553282Z","iopub.status.idle":"2022-08-26T12:52:47.66648Z","shell.execute_reply.started":"2022-08-26T12:52:47.553217Z","shell.execute_reply":"2022-08-26T12:52:47.665498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=data.copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-26T12:52:47.668954Z","iopub.execute_input":"2022-08-26T12:52:47.670243Z","iopub.status.idle":"2022-08-26T12:52:47.67662Z","shell.execute_reply.started":"2022-08-26T12:52:47.6702Z","shell.execute_reply":"2022-08-26T12:52:47.675575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-26T12:52:47.678241Z","iopub.execute_input":"2022-08-26T12:52:47.678939Z","iopub.status.idle":"2022-08-26T12:52:47.710605Z","shell.execute_reply.started":"2022-08-26T12:52:47.678902Z","shell.execute_reply":"2022-08-26T12:52:47.709619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare your data:\nLets clean the data remove any stoping words and punctuations, we will use NLTK and spacy for this","metadata":{}},{"cell_type":"markdown","source":"These lines first import the necessary libraries for text processing, including spaCy and NLTK. The 'spacy.load' method loads a pre-trained English language model for text processing, and the 'stop_words' attribute of that model is used to obtain a set of common English stopwords. Additional stopwords are then added to this set.","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom nltk.tokenize import word_tokenize\nsp = spacy.load('en_core_web_sm')\nall_stopwords = sp.Defaults.stop_words\nall_stopwords.add('&')\nall_stopwords.add(',')\nall_stopwords.add('.')\nall_stopwords.add('@')\nall_stopwords.add('/')\nall_stopwords.add(':')\nall_stopwords.add('?')","metadata":{"execution":{"iopub.status.busy":"2022-08-26T12:59:05.037754Z","iopub.execute_input":"2022-08-26T12:59:05.038293Z","iopub.status.idle":"2022-08-26T12:59:18.359568Z","shell.execute_reply.started":"2022-08-26T12:59:05.038238Z","shell.execute_reply":"2022-08-26T12:59:18.35868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'remove_Stopingwords_Punctuation' function is defined to remove stopwords and punctuation from text. The function first tokenizes the text using NLTK's 'word_tokenize' method, and then removes stopwords using a list comprehension. The resulting list of words is then joined back into a string using the 'join' method.","metadata":{}},{"cell_type":"code","source":"def remove_Stopingwords_Punctuation(text):\n    text_tokens = word_tokenize(text)\n    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n    return \" \".join(tokens_without_sw)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:00:25.045885Z","iopub.execute_input":"2022-08-26T13:00:25.046406Z","iopub.status.idle":"2022-08-26T13:00:25.053584Z","shell.execute_reply.started":"2022-08-26T13:00:25.046365Z","shell.execute_reply":"2022-08-26T13:00:25.051721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe next three lines apply the 'remove_Stopingwords_Punctuation' function to the 'ProductName' and 'Description' columns of the DataFrame, and concatenate the resulting strings with other relevant columns to form a 'Feature_Set' column.","metadata":{}},{"cell_type":"code","source":"df[\"ProductName\"]=df[\"ProductName\"].apply(lambda x : remove_Stopingwords_Punctuation(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:00:26.321431Z","iopub.execute_input":"2022-08-26T13:00:26.32235Z","iopub.status.idle":"2022-08-26T13:00:27.796411Z","shell.execute_reply.started":"2022-08-26T13:00:26.322307Z","shell.execute_reply":"2022-08-26T13:00:27.795286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Description\"]=df[\"Description\"].apply(lambda x : remove_Stopingwords_Punctuation(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:00:27.798217Z","iopub.execute_input":"2022-08-26T13:00:27.798555Z","iopub.status.idle":"2022-08-26T13:00:30.277657Z","shell.execute_reply.started":"2022-08-26T13:00:27.798526Z","shell.execute_reply":"2022-08-26T13:00:30.276481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Feature_Set\"]=df[\"ProductBrand\"]+df[\"ProductName\"]+df[\"Gender\"]+df[\"Description\"]+df[\"PrimaryColor\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:02:57.95917Z","iopub.execute_input":"2022-08-26T13:02:57.959655Z","iopub.status.idle":"2022-08-26T13:02:57.989489Z","shell.execute_reply.started":"2022-08-26T13:02:57.959622Z","shell.execute_reply":"2022-08-26T13:02:57.988062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset=df[[\"ProductID\",\"Feature_Set\"]]","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:03:04.324991Z","iopub.execute_input":"2022-08-26T13:03:04.325482Z","iopub.status.idle":"2022-08-26T13:03:04.342972Z","shell.execute_reply.started":"2022-08-26T13:03:04.325445Z","shell.execute_reply":"2022-08-26T13:03:04.341696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:03:10.115001Z","iopub.execute_input":"2022-08-26T13:03:10.115489Z","iopub.status.idle":"2022-08-26T13:03:10.132375Z","shell.execute_reply.started":"2022-08-26T13:03:10.115451Z","shell.execute_reply":"2022-08-26T13:03:10.131413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset.dropna(axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:05:33.639862Z","iopub.execute_input":"2022-08-26T13:05:33.640958Z","iopub.status.idle":"2022-08-26T13:05:33.659669Z","shell.execute_reply.started":"2022-08-26T13:05:33.640915Z","shell.execute_reply":"2022-08-26T13:05:33.658306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:05:39.638657Z","iopub.execute_input":"2022-08-26T13:05:39.639116Z","iopub.status.idle":"2022-08-26T13:05:39.646622Z","shell.execute_reply.started":"2022-08-26T13:05:39.639081Z","shell.execute_reply":"2022-08-26T13:05:39.644826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:05:45.043729Z","iopub.execute_input":"2022-08-26T13:05:45.044158Z","iopub.status.idle":"2022-08-26T13:06:02.371306Z","shell.execute_reply.started":"2022-08-26T13:05:45.044122Z","shell.execute_reply":"2022-08-26T13:06:02.369822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_embeddings = model.encode(subset[\"Feature_Set\"])","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:06:13.286845Z","iopub.execute_input":"2022-08-26T13:06:13.287373Z","iopub.status.idle":"2022-08-26T13:08:37.055741Z","shell.execute_reply.started":"2022-08-26T13:06:13.287331Z","shell.execute_reply":"2022-08-26T13:08:37.054573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:08:50.473917Z","iopub.execute_input":"2022-08-26T13:08:50.474329Z","iopub.status.idle":"2022-08-26T13:08:50.483167Z","shell.execute_reply.started":"2022-08-26T13:08:50.474296Z","shell.execute_reply":"2022-08-26T13:08:50.481936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset[\"Feature_Set\"].values","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:10:13.208708Z","iopub.execute_input":"2022-08-26T13:10:13.209162Z","iopub.status.idle":"2022-08-26T13:10:13.218527Z","shell.execute_reply.started":"2022-08-26T13:10:13.20913Z","shell.execute_reply":"2022-08-26T13:10:13.21701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:08:56.91923Z","iopub.execute_input":"2022-08-26T13:08:56.920183Z","iopub.status.idle":"2022-08-26T13:08:56.938578Z","shell.execute_reply.started":"2022-08-26T13:08:56.920138Z","shell.execute_reply":"2022-08-26T13:08:56.936869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product_id=10015921\ncosine_scores = util.cos_sim(model.encode(subset[subset[\"ProductID\"]==product_id][\"Feature_Set\"].values[0]), sentence_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:12:43.023295Z","iopub.execute_input":"2022-08-26T13:12:43.023759Z","iopub.status.idle":"2022-08-26T13:12:43.126909Z","shell.execute_reply.started":"2022-08-26T13:12:43.023726Z","shell.execute_reply":"2022-08-26T13:12:43.125873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score=cosine_scores[0].tolist()\nrecomendations_cos=[]\nfor i in range(0,5):\n    maxx=score.index(max(score))\n    recomendations_cos.append(subset['ProductID'][maxx])\n    score[maxx]=-1","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:12:43.718286Z","iopub.execute_input":"2022-08-26T13:12:43.718923Z","iopub.status.idle":"2022-08-26T13:12:43.726902Z","shell.execute_reply.started":"2022-08-26T13:12:43.718887Z","shell.execute_reply":"2022-08-26T13:12:43.72564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recomendations_cos","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:12:44.902484Z","iopub.execute_input":"2022-08-26T13:12:44.902892Z","iopub.status.idle":"2022-08-26T13:12:44.908551Z","shell.execute_reply.started":"2022-08-26T13:12:44.902859Z","shell.execute_reply":"2022-08-26T13:12:44.907755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"ProductID\"].isin(recomendations_cos)]","metadata":{"execution":{"iopub.status.busy":"2022-08-26T13:12:45.851772Z","iopub.execute_input":"2022-08-26T13:12:45.852243Z","iopub.status.idle":"2022-08-26T13:12:45.87046Z","shell.execute_reply.started":"2022-08-26T13:12:45.852207Z","shell.execute_reply":"2022-08-26T13:12:45.86932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}